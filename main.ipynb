{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 0 Information\n",
    "\n",
    "## 0.1 Prerequisites\n",
    "\n",
    "### 0.1.1 Git\n",
    "* Should be installed\n",
    "* Should be available via path, so that it is possible to call `git clone ...` directly from the console\n",
    "\n",
    "### 0.1.2 Python\n",
    "It is recommended to use version 3.8+. The oldest version on which\n",
    "this notebook and all codebase scripts have been tested is 3.7.\n",
    "\n",
    "### 0.1.3 tar\n",
    "This tool is required if you want to download the dataset and unzip it\n",
    "\n",
    "## 0.2 Recommendations\n",
    "\n",
    "### 0.2.1 Configuration\n",
    "The current setup of this file allow you to completely run all the modules of the project without any problems.\n",
    "If you wish to simply execute all the functions, and you don't require special configuration or output directories\n",
    "then please stick to the configuration that is provided here by default.\n",
    "\n",
    "### 0.2.2 Google colab\n",
    "A lot of scripts from here are very slow and it is advisable to run them from Google Colab. Also the whole testing was done on colab so it is a guarantee that everything works on Colab as intended. In Colab you don't have to care about virtual environments and packages in python.\n",
    "\n",
    "### 0.2.3 Virtual environment\n",
    "If you still decide to run the notebook locally, it is recommended to run this notebook in a separate `conda` python virtual environment.\n",
    "Even though this is not a hard requirement to run this notebook it is very recommended using a virtual environment.\n",
    "\n",
    "## 0.3 App\n",
    "This notebook does not contain the startup of the frontend for the animal detector app. For this, follow the instructions from the readme.md file of the github repo for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE_VERBOSE = 'verbose'\n",
    "MODE_SILENT = 'silent'\n",
    "\n",
    "DEFAULT_TRAINED_MODEL = 'my_model'\n",
    "\n",
    "DEFAULT_CONFIG_FILE = 'config_default.json'\n",
    "\n",
    "GITHUB_REPO_URL = 'https://github.com/Philideli/animal_detection.git'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Adjustable config constants\n",
    "Change these if you want to experiment with the functionality of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### `SCRIPTS_EXEC_MODE`\n",
    "It is possible to execute all scripts in `verbose` mode to display\n",
    "all logs that are displayed by the scripts themselves\n",
    "and also by all the subprocesses that they start. However, if you use `silent` mode\n",
    "then no logs will be displayed. Only important messages like errors and\n",
    "important execution checkpoints will be logged in silent mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SCRIPTS_EXEC_MODE = MODE_VERBOSE # MODE_SILENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### `EVAL_SPLIT_RATIO`\n",
    "Specify a float value from `0.0` to `1.0` which defines how big the part of images should\n",
    "be used for evaluation. Value of `0.2` means that 20% of all the images in the provided dataset\n",
    "should be used for evaluation. The rest is used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EVAL_SPLIT_RATIO = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### `NUM_TRAIN_STEPS`\n",
    "The number of training steps during the model training process. See TFOD API documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_TRAIN_STEPS = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `CHECKPOINT_EVERY_N`\n",
    "How often should Tensorflow make checkpoints of training status. See TFOD API documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_EVERY_N = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `EXISTING_MODEL`\n",
    "\n",
    "If you do not need to train the model, please specify the name of the trained model here and put its weights in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXISING_MODEL = None # set to DEFAULT_TRAINED_MODEL if my_model is present and no training is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DOWNLOAD_DATASET`\n",
    "Set to `True` if the dataset should be downloaded from the servers (https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz and https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_DATASET = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2 Workspace preparation\n",
    "All of these cells should be run only for one time when we \"start from scratch\" with this notebook\n",
    "Install the project package to the python (virtual) environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone {GITHUB_REPO_URL} ./animal_detection\n",
    "\n",
    "import shutil\n",
    "shutil.copy('./animal_detection/setup.py', './setup.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', '-e', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ./animal_detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m pip install django django-cors-headers django-rest-framework django-composite-field mysqlclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Download archive with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD_DATASET:\n",
    "    import urllib, os\n",
    "    urllib.request.urlretrieve(\"https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz\", \"annotations.tar.gz\")\n",
    "    print('downloaded annotations')\n",
    "    urllib.request.urlretrieve(\"https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\", \"images.tar.gz\")\n",
    "    print('downloaded images')\n",
    "    \n",
    "    os.makedirs('./data/datasets/raw/my_dataset/annotations', exist_ok=True)\n",
    "    os.makedirs('./data/datasets/raw/my_dataset/images', exist_ok=True)\n",
    "    !tar -zxf ./annotations.tar.gz --directory ./data/datasets/raw/my_dataset/annotations\n",
    "    !tar -zxf ./images.tar.gz --directory ./data/datasets/raw/my_dataset/images\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3 TFOD API and pretrained model\n",
    "Here we install Tensorflow Object Detection API and\n",
    "load the pretrained model that is specified in the config.\n",
    "Generally, the TFOD API should only be installed once.\n",
    "However, several pretrained models can be loaded (when the config is changed)\n",
    "and in this case it is required to run these cells once again\n",
    "for the new pretrained model to be used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "python_file = os.path.join('setup', 'workspace.py')\n",
    "! python {python_file} -m {SCRIPTS_EXEC_MODE} -v \"both\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code above installs some packages with incorrect versions and\n",
    "# we need to reinstall these packages with correct versions\n",
    "# for correct functionality of other parts of this notebook\n",
    "! python -m pip install matplotlib scikit-learn pillow pytz gin-config tensorflow[and-cuda]==2.13.0 opencv-python\n",
    "\n",
    "# it sometimes also helps to rerun the cell above after running this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4 Dataset preparation\n",
    "Here we create the processed dataset with splitting into train and test sets.\n",
    "Please put your raw data in ./data/datasets/raw/my_dataset if not done in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "python_file = os.path.join('data', 'preparation.py')\n",
    "!python {python_file} -m {SCRIPTS_EXEC_MODE} -sr {EVAL_SPLIT_RATIO}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5 Train the model\n",
    "Train the model on the created TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "python_file = os.path.join('models', 'train.py')\n",
    "!python {python_file} -m {SCRIPTS_EXEC_MODE} --num_train_steps {NUM_TRAIN_STEPS} --checkpoint_every_n {CHECKPOINT_EVERY_N}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6 Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "python_file = os.path.join('models', 'eval.py')\n",
    "!python {python_file} -m {SCRIPTS_EXEC_MODE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 7 Image Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = r'put the path for the image that you want to execute detection on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "python_file = os.path.join('detect', 'detect_objects.py')\n",
    "!python {python_file} --image-path \"{IMAGE_PATH}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
